# LMAX Disruptor：在并发线程之间交换数据的高性能有界队列的替代方案

>摘要
> 
>LMAX致力于创建一个高性能的金融交易所。在我们实现这一目标的过程中，我们评估了几种方法，但在测量这些方法时，我们遇到了一些传统方法的基本限制。
许多应用程序依赖于队列来在处理阶段之间交换数据。我们的性能测试表明，使用队列进行此类操作时，延迟成本与将数据写入磁盘（基于RAID或SSD的磁盘系统）的成本相同，这会大大降低性能。如果在端到端操作中存在多个队列，则会增加数百微秒的延迟。显然有优化的空间。
进一步研究并关注计算机科学，让我们意识到传统方法所固有的关注点混杂问题（例如队列和处理节点）在多线程实现中会导致争用，这表明可能有更好的方法。
考虑现代CPU的工作方式，我们喜欢称之为“机械同理心”，使用良好的设计实践和强烈关注各个方面，我们提出了一种数据结构和使用模式，我们称之为Disruptor。
测试表明，在使用Disruptor进行三级流水线的情况下，平均延迟比等效的基于队列的方法低了3个数量级。此外，Disruptor可以处理大约8倍的吞吐量，而使用相同配置的队列。
这些性能改进代表了并发编程思维的一个飞跃。这种新的模式是任何需要高吞吐量和低延迟的异步事件处理体系结构的理想基础。
在LMAX，我们已经在这种模式上构建了订单匹配引擎、实时风险管理和高度可用的内存事务处理系统，并取得了巨大的成功。我们的每个系统都树立了新的性能标准，我们认为这些标准是无可匹敌的。
但是，这不是仅适用于金融行业的专业解决方案。Disruptor是一种通用机制，以最大化性能并且易于实现的方式解决了并发编程中的复杂问题。虽然其中一些概念可能看起来不寻常，但我们的经验表明，使用这种模式构建的系统比可比机制更容易实现。
Disruptor的写入争用明显较少，并发开销更低，比类似方法更友好缓存，这都导致了更高的吞吐量，

## 1. 概述
Disruptor是我们在LMAX致力于构建全球最高性能金融交易所的努力的结果。早期的设计侧重于基于SEDA[1]和Actor[2]的体系结构，使用管道实现吞吐量。在对各种实现进行分析后，我们发现在管道中的事件排队成为了主要的成本。我们发现队列还会引入延迟和高级别的抖动。我们花费了大量的精力开发了具有更好性能的新队列实现。然而，队列作为一种基本数据结构受制于生产者、消费者和它们的数据存储的设计关注点混淆的局限性。 Disruptor是我们致力于构建一个清晰地分离这些关注点的并发结构的努力的结果。
并发的复杂性
在本文及计算机科学的语境中，并发不仅意味着两个或更多任务同时进行，而且意味着它们争夺对资源的访问。争夺资源可以是数据库、文件、套接字甚至是内存中的位置。
代码的并发执行涉及两个方面，即互斥和变更的可见性。互斥是指管理对某些资源的争夺更新。变更的可见性则是控制何时将这些更改对其他线程进行可见。如果您的算法可以保证任何给定资源仅由一个线程修改，则可以避免需要互斥。读写操作要求将所有更改对其他线程进行可见。但只有争夺写入操作需要更改的互斥。

## 2. 并发的复杂性
在本文及计算机科学的语境中，并发不仅意味着两个或更多任务同时进行，而且意味着它们争夺对资源的访问。争夺资源可以是数据库、文件、套接字甚至是内存中的位置。

代码的并发执行涉及两个方面，即互斥和变更的可见性。互斥是指管理对某些资源的争夺更新。变更的可见性则是控制何时将这些更改对其他线程进行可见。如果您的算法可以保证任何给定资源仅由一个线程修改，则可以避免需要互斥。读写操作要求将所有更改对其他线程进行可见。但只有争夺写入操作需要更改的互斥。

任何并发环境中最昂贵的操作是争夺写入访问。使多个线程写入同一资源需要复杂和昂贵的协调。通常通过采用一种锁定策略来实现。

### 2.1. 锁的成本
锁提供了互斥并确保更改的可见性按顺序进行。锁的成本非常昂贵，因为它们在争用时需要仲裁。这种仲裁通过上下文切换到操作系统内核来实现，该内核将挂起等待锁释放的线程。在这样的上下文切换期间，执行上下文可能会失去以前缓存的数据和指令。这可能会对现代处理器产生严重的性能影响。可以使用快速用户模式锁，但仅在没有争用时才能真正受益。

我们将用一个简单的演示来说明锁的成本。这个实验的重点是循环调用一个函数，该函数将一个64位计数器递增500亿次。如果使用Java语言编写，可以在2.4Ghz Intel Westmere EP上的单个线程上仅用300ms执行。这个实验的语言不重要，使用相同的基本原语，结果会类似。

一旦引入锁来提供互斥，即使锁尚未争用，成本也会显著增加。当两个或更多的线程开始争用时，成本再次增加数倍。下面的表格显示了这个简单实验的结果：

### 2.2. “CAS”的成本
更新单个字的内存时，比使用锁更有效的替代方法可以应用基于现代处理器实现的原子或交错指令。这些指令通常称为CAS（Compare And Swap）操作，例如在x86上的“lock cmpxchg”。CAS操作是一种特殊的机器码指令，允许将内存中的字作为条件设置为原子操作。对于“增加计数器实验”，每个线程可以在循环中旋转读取计数器，然后尝试以原子方式将其设置为其新的递增值。旧值和新值作为参数提供给此指令。如果执行操作时计数器的值与提供的期望值匹配，则使用新值更新计数器。另一方面，如果值不如预期，则CAS操作将失败。然后由尝试执行更改的线程重新尝试，从该值重新读取计数器增量，以此类推，直到更改成功。这种CAS方法比锁要高效得多，因为它不需要上下文切换到内核进行仲裁。但是，CAS操作并非没有成本。处理器必须锁定其指令管道以确保原子性，并使用内存屏障将更改对其他线程可见。通过使用java.util.concurrent.Atomic*类，可以在Java中使用CAS操作。

如果程序的关键部分比简单的计数器递增更复杂，则可能需要使用多个CAS操作的复杂状态机来编排争用。使用锁开发并发程序很困难；使用CAS操作和内存屏障开发无锁算法要复杂得多，而且很难证明它们是正确的。

理想的算法将是只有一个线程拥有对单个资源的所有写操作，而其他线程读取结果。在多处理器环境中读取结果需要使用内存屏障，以使更改对运行在其他处理器上的线程可见。

### 2.3. 内存屏障
现代处理器对指令和数据进行乱序执行和乱序加载和存储，以提高性能。处理器只需保证程序逻辑产生相同的结果，无论执行顺序如何即可。对于单线程程序，这不是问题。但是，当线程共享状态时，所有内存更改出现的顺序对于数据交换的成功非常重要。内存屏障由处理器用于指示内存更新的顺序很重要的代码段。它们是处理器之间实现硬件排序和更改可见性的手段。编译器可以实现补充的软件屏障以确保编译代码的顺序，这些软件内存屏障是处理器本身使用的硬件屏障的补充。

现代 CPU 的速度现在比当前一代内存系统快得多。为了弥补这种差距，CPU 使用了复杂的缓存系统，这些系统实际上是没有链接的快速硬件哈希表。通过消息传递协议，这些缓存与其他处理器缓存系统保持一致。此外，处理器还有“存储缓冲区”用于卸载写入这些缓存的写操作，以及“失效队列”，使得缓存一致性协议可以在写操作即将发生时快速确认失效消息，以提高效率。

对于数据来说，这意味着任何值的最新版本在被写入后的任何阶段都可能位于寄存器、存储缓冲区、多层缓存中的其中一个，或者位于主存储器中。如果线程要共享此值，则需要以有序的方式进行可见，这是通过协调缓存一致性消息的交换来实现的。内存屏障可以控制生成这些消息的及时性。

读内存屏障通过在缓存中标记一个无效队列中的点，对执行它的 CPU 上的加载指令进行排序，从而为读取屏障之前排序的写入操作提供一致的视图。

写内存屏障通过在存储缓冲区中标记一个点对执行它的 CPU 上的存储指令进行排序，从而通过其缓存将写操作刷新出去。这个屏障为世界提供了一个有序的视图，表明什么存储操作发生在写屏障之前。

完全内存屏障同时对加载和存储进行排序，但仅在执行它的 CPU 上进行排序。

一些 CPU 还有其他的变体，但这三个原语足以理解其中的复杂性。在 Java 内存模型中，volatile 字段的读取和写入分别实现了读写屏障。这在 Java 5 发布时的 Java 内存模型 [3] 中被明确规定。

### 2.4. 缓存行
现代处理器中缓存使用的方式对于高性能操作至关重要。这些处理器在缓存中处理数据和指令时非常高效，但相比之下，当出现缓存未命中时效率却非常低下。

硬件并不是以字节或字为单位移动内存。为了提高效率，缓存被组织成缓存行，其大小通常为32-256字节，其中最常见的缓存行大小为64字节。这是缓存一致性协议运作的粒度级别。这意味着，如果两个变量位于同一缓存行中，并且它们由不同的线程进行写入，则它们会出现写入争用的问题，就像它们是单个变量一样。这是一个称为“虚假共享”的概念。因此，为了实现高性能，重要的是要确保独立但同时进行写入的变量不共享同一缓存行，以最小化争用。

当以可预测的方式访问内存时，处理器能够通过预测下一个可能被访问的内存并在后台预取它来隐藏访问主内存的延迟成本。这仅在处理器能够检测到访问模式时才起作用，例如使用可预测的“步幅”遍历内存。当迭代数组内容时，步幅是可预测的，因此内存将以缓存行的方式预取，最大化访问效率。步幅通常必须小于2048个字节以内或以外，才能被处理器注意到。然而，像链表和树这样的数据结构往往具有在内存中更广泛分布且没有可预测的访问步幅的节点。内存中缺乏一致的模式会限制系统预取缓存行的能力，导致主内存访问效率比缓存访问效率低2个数量级以上。

### 2.5. 队列的问题
队列通常使用链表或数组作为元素的基本存储方式。如果允许内存中的队列无限制增长，那么对于许多问题，它们可能会无限制地增长直至耗尽内存，导致灾难性的失败。这种情况通常在生产者的速度快于消费者时发生。虽然无限制队列在生产者的速度不会超过消费者且内存是宝贵资源的系统中非常有用，但是如果这种假设不成立，队列将无限制增长，存在风险。为了避免这种灾难性的结果，队列通常会限制大小（有界）。保持队列有界需要其基于数组或者要跟踪大小。

队列实现倾向于在头部、尾部和大小变量上存在写争用。在使用时，由于生产者和消费者之间的速度差异，队列通常始终接近满或接近空。它们很少在生产和消费速率相匹配的平衡中运行。这倾向于始终满或始终空，导致高水平的争用和/或昂贵的缓存一致性。问题在于，即使使用不同的并发对象（如锁或CAS变量）将头和尾机制分离，它们通常占用同一个缓存行。

管理生产者声明队列头、消费者声明队列尾以及在节点之间存储的问题，使得并发实现的设计非常复杂，除了使用单个大粒度锁之外，难以进行更细粒度的处理。针对放置和获取操作整个队列的大粒度锁实现简单，但对吞吐量产生显着的瓶颈。如果并发问题可以在队列的语义中分开，则除单个生产者-单个消费者实现外，实现变得非常复杂。

在Java中，使用队列存在另一个问题，它们是垃圾的重要来源。首先，必须分配对象并将其放入队列中。其次，如果是链表支持的，则必须分配对象来表示列表的节点。当不再引用时，所有分配用于支持队列实现的对象都需要被回收。

### 2.6. 管道和图形
对于许多问题类别来说，将几个处理阶段连接起来形成管道是有意义的。这些管道通常有并行路径，并组织成图形拓扑结构。每个阶段之间的链接通常通过队列来实现，每个阶段都有自己的线程。

这种方法并不便宜 - 在每个阶段，我们必须承担入队和出队工作单元的成本。当路径必须分叉时，目标的数量将增加这个成本，并在此类分叉后重新加入时产生必然的竞争成本。

如果能够表达依赖关系图形而不产生在阶段之间放置队列的成本，那就太理想了。

---

